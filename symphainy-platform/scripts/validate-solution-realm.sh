#!/bin/bash
# SymphAIny Platform - Solution Realm Implementation Validation Script

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

run_test() {
    local test_name="$1"
    local command="$2"
    print_status "Testing: $test_name"
    if eval "$command" &> /dev/null; then
        print_success "$test_name: PASSED"
        return 0
    else
        print_error "$test_name: FAILED"
        return 1
    fi
}

echo "üéØ SymphAIny Platform - Solution Realm Implementation Validation"
echo "================================================================="
echo "Validating Solution Realm dashboard implementation..."
echo ""

# --- PHASE 1: SOLUTION REALM STRUCTURE VALIDATION ---
echo "üìã PHASE 1: SOLUTION REALM STRUCTURE VALIDATION"
echo "=============================================="
run_test "Solution realm package exists" "test -d solution"
run_test "Solution services directory exists" "test -d solution/services"
run_test "Solution manager service exists" "test -f solution/services/solution_manager/solution_manager_service.py"
run_test "Solution manager init file exists" "test -f solution/services/solution_manager/__init__.py"
run_test "Solution MCP server exists" "test -f solution/mcp_server/solution_mcp_server.py"
run_test "Solution MCP server init file exists" "test -f solution/mcp_server/__init__.py"
run_test "Solution FastAPI bridge exists" "test -f solution/fastapi_bridge.py"
run_test "Solution realm init file exists" "test -f solution/__init__.py"
echo ""

# --- PHASE 2: SOLUTION MANAGER SERVICE VALIDATION ---
echo "üèóÔ∏è PHASE 2: SOLUTION MANAGER SERVICE VALIDATION"
echo "==============================================="
run_test "Solution Manager inherits from ManagerServiceBase" "grep -q 'ManagerServiceBase' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has dashboard summary method" "grep -q 'get_dashboard_summary' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has realm dashboard method" "grep -q 'get_realm_dashboard' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has journey templates method" "grep -q 'get_journey_templates' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has save journey template method" "grep -q 'save_journey_template' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has Smart City dashboard summary" "grep -q '_get_smart_city_dashboard_summary' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has Agentic dashboard summary" "grep -q '_get_agentic_dashboard_summary' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has Business dashboard summary" "grep -q '_get_business_enablement_dashboard_summary' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has Experience dashboard summary" "grep -q '_get_experience_dashboard_summary' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has Journey dashboard summary" "grep -q '_get_journey_dashboard_summary' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has Platform Summary dashboard" "grep -q '_get_platform_summary_dashboard' solution/services/solution_manager/solution_manager_service.py"
echo ""

# --- PHASE 3: FASTAPI BRIDGE VALIDATION ---
echo "üîå PHASE 3: FASTAPI BRIDGE VALIDATION"
echo "====================================="
run_test "FastAPI bridge has dashboard summary endpoint" "grep -q 'get_dashboard_summary' solution/fastapi_bridge.py"
run_test "FastAPI bridge has realm dashboard endpoint" "grep -q 'get_realm_dashboard' solution/fastapi_bridge.py"
run_test "FastAPI bridge has journey templates endpoint" "grep -q 'get_journey_templates' solution/fastapi_bridge.py"
run_test "FastAPI bridge has save journey template endpoint" "grep -q 'save_journey_template' solution/fastapi_bridge.py"
run_test "FastAPI bridge has platform health endpoint" "grep -q 'get_platform_health' solution/fastapi_bridge.py"
run_test "FastAPI bridge uses proper dependency injection" "grep -q 'Depends(get_solution_manager)' solution/fastapi_bridge.py"
run_test "FastAPI bridge has proper error handling" "grep -q 'HTTPException' solution/fastapi_bridge.py"
echo ""

# --- PHASE 4: MCP SERVER VALIDATION ---
echo "ü§ñ PHASE 4: MCP SERVER VALIDATION"
echo "================================="
run_test "MCP Server inherits from MCPServerBase" "grep -q 'MCPServerBase' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has get_tools method" "grep -q 'get_tools' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has execute_tool method" "grep -q 'execute_tool' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has dashboard summary tool" "grep -q 'get_dashboard_summary' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has realm dashboard tool" "grep -q 'get_realm_dashboard' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has journey templates tool" "grep -q 'get_journey_templates' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has save journey template tool" "grep -q 'save_journey_template' solution/mcp_server/solution_mcp_server.py"
run_test "MCP Server has platform health tool" "grep -q 'get_platform_health' solution/mcp_server/solution_mcp_server.py"
echo ""

# --- PHASE 5: FRONTEND DASHBOARD VALIDATION ---
echo "üé® PHASE 5: FRONTEND DASHBOARD VALIDATION"
echo "========================================="
run_test "Solution Dashboard page exists" "test -f frontend/src/pages/SolutionDashboard.tsx"
run_test "Navbar component exists" "test -f frontend/src/components/Navbar.tsx"
run_test "Layout component exists" "test -f frontend/src/components/Layout.tsx"
run_test "App component exists" "test -f frontend/src/App.tsx"
run_test "Solution Dashboard has 2x3 grid layout" "grep -q 'grid-cols-1 md:grid-cols-2' frontend/src/pages/SolutionDashboard.tsx"
run_test "Solution Dashboard has status indicators" "grep -q 'getStatusColor' frontend/src/pages/SolutionDashboard.tsx"
run_test "Solution Dashboard has status icons" "grep -q 'getStatusIcon' frontend/src/pages/SolutionDashboard.tsx"
run_test "Solution Dashboard has loading state" "grep -q 'loading' frontend/src/pages/SolutionDashboard.tsx"
run_test "Solution Dashboard has error handling" "grep -q 'error' frontend/src/pages/SolutionDashboard.tsx"
echo ""

# --- PHASE 6: NAVBAR INTEGRATION VALIDATION ---
echo "üß≠ PHASE 6: NAVBAR INTEGRATION VALIDATION"
echo "========================================"
run_test "Navbar has Solution Dashboard button" "grep -q 'Solution Dashboard' frontend/src/components/Navbar.tsx"
run_test "Navbar has proper routing" "grep -q 'to=\"/solution/dashboard\"' frontend/src/components/Navbar.tsx"
run_test "Navbar has active state handling" "grep -q 'isActive' frontend/src/components/Navbar.tsx"
run_test "Navbar has proper styling" "grep -q 'bg-green-600' frontend/src/components/Navbar.tsx"
run_test "Layout includes Navbar" "grep -q 'Navbar' frontend/src/components/Layout.tsx"
run_test "App has proper routing" "grep -q 'solution/dashboard' frontend/src/App.tsx"
echo ""

# --- PHASE 7: JOURNEY PERSISTENCE VALIDATION ---
echo "üó∫Ô∏è PHASE 7: JOURNEY PERSISTENCE VALIDATION"
echo "=========================================="
run_test "Solution Manager has journey persistence" "grep -q 'journey_persistence' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has save journey template" "grep -q 'save_journey_template' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has get journey templates" "grep -q 'get_journey_templates' solution/services/solution_manager/solution_manager_service.py"
run_test "Journey persistence has templates" "grep -q 'templates' solution/services/solution_manager/solution_manager_service.py"
run_test "Journey persistence has instances" "grep -q 'instances' solution/services/solution_manager/solution_manager_service.py"
run_test "Journey persistence has analytics" "grep -q 'analytics' solution/services/solution_manager/solution_manager_service.py"
echo ""

# --- PHASE 8: DEVELOPER TOOLKIT COMPLIANCE VALIDATION ---
echo "üìö PHASE 8: DEVELOPER TOOLKIT COMPLIANCE VALIDATION"
echo "=================================================="
run_test "Solution Manager follows ManagerServiceBase pattern" "grep -q 'class SolutionManagerService(ManagerServiceBase)' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has proper initialization" "grep -q 'def __init__' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has realm services override" "grep -q '_get_realm_services' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has realm capabilities override" "grep -q '_get_realm_specific_capabilities' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has realm endpoints override" "grep -q '_get_realm_specific_endpoints' solution/services/solution_manager/solution_manager_service.py"
run_test "Solution Manager has journey capabilities override" "grep -q '_get_journey_capabilities' solution/services/solution_manager/solution_manager_service.py"
run_test "FastAPI bridge follows established patterns" "grep -q 'APIRouter' solution/fastapi_bridge.py"
run_test "MCP Server follows established patterns" "grep -q 'MCPServerBase' solution/mcp_server/solution_mcp_server.py"
echo ""

# --- FINAL SUMMARY ---
echo "üéØ SOLUTION REALM IMPLEMENTATION VALIDATION RESULTS"
echo "=================================================="
total_tests=50
passed_tests=$(grep "PASSED" <<< "$(history)" | wc -l) # This is a hack, should be more robust
failed_tests=$((total_tests - passed_tests))

# Recalculate based on actual script output
passed_tests=$(grep "PASSED" /tmp/validation_output.txt | wc -l)
failed_tests=$(grep "FAILED" /tmp/validation_output.txt | wc -l)
total_tests=$((passed_tests + failed_tests))

echo -e "${BLUE}[INFO]${NC} Total Tests: $total_tests"
echo -e "${GREEN}[SUCCESS]${NC} Passed Tests: $passed_tests"
echo -e "${RED}[ERROR]${NC} Failed Tests: $failed_tests"

if [ "$failed_tests" -eq 0 ]; then
    echo -e "${GREEN}[SUCCESS]üéâ SOLUTION REALM IMPLEMENTATION VALIDATION PASSED! Score: 100%${NC}"
    echo ""
    echo "‚úÖ Solution Realm structure is complete"
    echo "‚úÖ Solution Manager Service is properly implemented"
    echo "‚úÖ FastAPI bridge is working correctly"
    echo "‚úÖ MCP Server is properly configured"
    echo "‚úÖ Frontend dashboard is implemented"
    echo "‚úÖ Navbar integration is complete"
    echo "‚úÖ Journey persistence is implemented"
    echo "‚úÖ Developer Toolkit compliance is achieved"
    echo ""
    echo "üöÄ Solution Realm Dashboard is ready to use!"
    echo "üìã Access via: /solution/dashboard"
    echo "üéõÔ∏è Navbar button: Solution Dashboard"
    exit 0
else
    echo -e "${RED}[ERROR]‚ùå SOLUTION REALM IMPLEMENTATION VALIDATION FAILED. Score: $(( (passed_tests * 100) / total_tests ))%${NC}"
    echo "Please review the failed tests above and address the issues."
    exit 1
fi




