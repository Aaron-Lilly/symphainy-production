# Saga Integration Detailed Implementation Plan
## "Capability by Design, Optional by Policy" Integration into Critical Operations

**Date:** January 2025  
**Status:** ğŸ“‹ **DETAILED IMPLEMENTATION PLAN**  
**Pattern:** "Capability by Design, Optional by Policy" (inspired by "Secure by Design, Open by Policy")

---

## ğŸ¯ Executive Summary

This plan provides a comprehensive roadmap for integrating **Saga Journey Orchestrator** into critical operations across the platform, following the "Capability by Design, Optional by Policy" pattern.

**Key Principle:** Build Saga capability into the architecture for critical multi-step operations, but make it optional and policy-driven to avoid complexity overload.

**Current State:**
- âœ… Saga Journey Orchestrator implemented as service
- âœ… Saga pattern documented and tested
- âŒ Not integrated into Solution â†’ Journey â†’ Realm flows
- âŒ Not policy-driven (not optional)
- âŒ No compensation handlers defined for platform operations

**Target State:**
- âœ… Saga available to all critical multi-step workflows (optional via policy)
- âœ… Compensation handlers defined for all critical operations
- âœ… Platform changes to support Saga integration
- âœ… Policy-driven enablement/disablement
- âœ… Comprehensive testing and validation

---

## ğŸ—ï¸ Architecture Integration Pattern

### "Capability by Design, Optional by Policy"

**"Capability by Design":**
- Saga capability built into Solution Orchestrators
- Available to all multi-step workflows
- Automatic compensation on failure
- Compensation handlers defined per operation

**"Optional by Policy":**
- Enable/disable via policy configuration
- Policy determines which workflows need Saga guarantees
- Default: Saga available but not required
- No overhead when disabled

### Integration Flow

```
Solution Orchestrator
  â†“ (if Saga enabled by policy)
Saga Journey Orchestrator
  â†“ (composes)
Structured Journey Orchestrator
  â†“ (executes)
Journey Orchestrator
  â†“ (delegates to)
Services (Realm)
```

---

## ğŸ“‹ Critical Operations for Saga Integration

### 1. Data Operations

#### 1.1 Data Ingestion Pipeline (Ingest â†’ Parse â†’ Embed â†’ Expose)

**Why Saga?**
- Multi-step pipeline spanning multiple services
- Partial failures leave data in inconsistent state
- Need to rollback uploaded files if parsing/embedding fails

**Milestones:**
1. **Ingest**: Upload file to storage
2. **Parse**: Extract structured content
3. **Embed**: Create semantic embeddings
4. **Expose**: Make available in semantic layer

**Compensation Handlers:**
```python
compensation_handlers = {
    "ingest": "delete_uploaded_file",
    "parse": "mark_file_as_unparsed",
    "embed": "delete_embeddings",
    "expose": "remove_from_semantic_layer"
}
```

**Integration Point:**
- `DataSolutionOrchestratorService.orchestrate_data_ingest()` â†’ Full pipeline
- Or individual steps if called separately

**Policy Configuration:**
```python
saga_policy = {
    "enable_saga": True,  # Enabled for data pipeline
    "saga_operations": ["data_ingest_pipeline"],
    "compensation_handlers": {
        "data_ingest_pipeline": {
            "ingest": "delete_uploaded_file",
            "parse": "mark_file_as_unparsed",
            "embed": "delete_embeddings",
            "expose": "remove_from_semantic_layer"
        }
    }
}
```

#### 1.2 Data Mapping (Source â†’ Target Transformation)

**Why Saga?**
- Multi-step mapping process
- Partial mappings leave data inconsistent
- Need to rollback if target transformation fails

**Milestones:**
1. **Analyze Source**: Extract source schema
2. **Analyze Target**: Extract target schema
3. **Generate Mapping**: Create transformation rules
4. **Apply Mapping**: Transform data
5. **Validate**: Verify transformation correctness

**Compensation Handlers:**
```python
compensation_handlers = {
    "analyze_source": "revert_source_analysis",
    "analyze_target": "revert_target_analysis",
    "generate_mapping": "delete_mapping_rules",
    "apply_mapping": "revert_transformation",
    "validate": "mark_as_invalid"
}
```

**Integration Point:**
- `InsightsSolutionOrchestratorService.orchestrate_insights_mapping()`

---

### 2. Operations Operations

#### 2.1 SOP to Workflow Conversion

**Why Saga?**
- Multi-step conversion process
- Partial conversion leaves documents inconsistent
- Need to rollback if workflow generation fails

**Milestones:**
1. **Extract SOP Structure**: Parse SOP document
2. **Analyze Workflow Requirements**: Determine workflow needs
3. **Generate Workflow**: Create workflow structure
4. **Validate Workflow**: Verify workflow correctness
5. **Store Workflow**: Save to data mash

**Compensation Handlers:**
```python
compensation_handlers = {
    "extract_sop_structure": "revert_sop_parsing",
    "analyze_workflow_requirements": "clear_analysis_cache",
    "generate_workflow": "delete_workflow_draft",
    "validate_workflow": "mark_workflow_as_invalid",
    "store_workflow": "delete_stored_workflow"
}
```

**Integration Point:**
- `OperationsSolutionOrchestratorService.orchestrate_operations_workflow_generation()`

#### 2.2 Coexistence Analysis (SOP + Workflow â†’ Blueprint)

**Why Saga?**
- Multi-step analysis spanning multiple documents
- Partial analysis leaves blueprints incomplete
- Need to rollback if blueprint generation fails

**Milestones:**
1. **Fetch SOP Content**: Retrieve SOP from data mash
2. **Fetch Workflow Content**: Retrieve workflow from data mash
3. **Analyze Coexistence**: Determine human-AI interaction points
4. **Generate Blueprint**: Create coexistence blueprint
5. **Store Blueprint**: Save blueprint to data mash

**Compensation Handlers:**
```python
compensation_handlers = {
    "fetch_sop_content": "clear_sop_cache",
    "fetch_workflow_content": "clear_workflow_cache",
    "analyze_coexistence": "revert_analysis",
    "generate_blueprint": "delete_blueprint_draft",
    "store_blueprint": "delete_stored_blueprint"
}
```

**Integration Point:**
- `OperationsSolutionOrchestratorService.orchestrate_operations_coexistence_analysis()`
- `OperationsSolutionOrchestratorService.orchestrate_ai_optimized_blueprint()`

#### 2.3 Interactive SOP Creation (Wizard)

**Why Saga?**
- Multi-step wizard process
- Partial creation leaves sessions inconsistent
- Need to rollback if final publish fails

**Milestones:**
1. **Start Wizard**: Initialize wizard session
2. **Collect Steps**: Gather SOP sections via chat
3. **Generate SOP**: Create SOP structure
4. **Validate SOP**: Verify SOP correctness
5. **Publish SOP**: Store final SOP

**Compensation Handlers:**
```python
compensation_handlers = {
    "start_wizard": "delete_wizard_session",
    "collect_steps": "clear_wizard_state",
    "generate_sop": "delete_sop_draft",
    "validate_sop": "mark_sop_as_invalid",
    "publish_sop": "delete_published_sop"
}
```

**Integration Point:**
- `OperationsSolutionOrchestratorService.orchestrate_interactive_sop_creation_start()`
- `OperationsSolutionOrchestratorService.orchestrate_interactive_sop_creation_publish()`

---

### 3. Business Outcomes Operations

#### 3.1 Pillar Summary Compilation

**Why Saga?**
- Multi-pillar data aggregation
- Partial compilation leaves summaries incomplete
- Need to rollback if compilation fails

**Milestones:**
1. **Fetch Content Summary**: Get content pillar data
2. **Fetch Insights Summary**: Get insights pillar data
3. **Fetch Operations Summary**: Get operations pillar data
4. **Compile Summaries**: Aggregate all pillar data
5. **Store Summary**: Save compiled summary

**Compensation Handlers:**
```python
compensation_handlers = {
    "fetch_content_summary": "clear_content_cache",
    "fetch_insights_summary": "clear_insights_cache",
    "fetch_operations_summary": "clear_operations_cache",
    "compile_summaries": "delete_compiled_summary",
    "store_summary": "delete_stored_summary"
}
```

**Integration Point:**
- `BusinessOutcomesSolutionOrchestratorService.orchestrate_pillar_summaries_compilation()`

#### 3.2 Roadmap Generation

**Why Saga?**
- Multi-step strategic planning process
- Partial generation leaves roadmaps incomplete
- Need to rollback if roadmap generation fails

**Milestones:**
1. **Analyze Pillar Outputs**: Review all pillar summaries
2. **Identify Opportunities**: Find AI value opportunities
3. **Generate Roadmap Structure**: Create roadmap framework
4. **Apply Business Logic**: Add financial/strategic analysis
5. **Store Roadmap**: Save final roadmap

**Compensation Handlers:**
```python
compensation_handlers = {
    "analyze_pillar_outputs": "clear_analysis_cache",
    "identify_opportunities": "revert_opportunity_identification",
    "generate_roadmap_structure": "delete_roadmap_draft",
    "apply_business_logic": "revert_business_analysis",
    "store_roadmap": "delete_stored_roadmap"
}
```

**Integration Point:**
- `BusinessOutcomesSolutionOrchestratorService.orchestrate_roadmap_generation()`

#### 3.3 POC Proposal Generation

**Why Saga?**
- Multi-step POC definition process
- Partial generation leaves POCs incomplete
- Need to rollback if POC generation fails

**Milestones:**
1. **Analyze Requirements**: Review roadmap and opportunities
2. **Calculate Financials**: Compute ROI, NPV, IRR
3. **Assess Risk**: Evaluate implementation risks
4. **Generate POC Structure**: Create POC proposal
5. **Store POC**: Save final POC proposal

**Compensation Handlers:**
```python
compensation_handlers = {
    "analyze_requirements": "clear_requirements_cache",
    "calculate_financials": "revert_financial_calculations",
    "assess_risk": "revert_risk_assessment",
    "generate_poc_structure": "delete_poc_draft",
    "store_poc": "delete_stored_poc"
}
```

**Integration Point:**
- `BusinessOutcomesSolutionOrchestratorService.orchestrate_poc_proposal_generation()`

---

## ğŸ”§ Platform Changes Required

### 1. Solution Orchestrator Changes

#### 1.1 Add Saga Policy Configuration

**Location:** All Solution Orchestrators (`*_solution_orchestrator_service.py`)

**Changes:**
- Add `_saga_enabled()` method (similar to `_wal_enabled()`)
- Add `_saga_policy` attribute
- Add `_get_saga_journey_orchestrator()` helper method
- Add `_execute_with_saga()` helper method

**Implementation Pattern:**
```python
class DataSolutionOrchestratorService(OrchestratorBase):
    def __init__(self, ...):
        # Saga policy (capability by design, optional by policy)
        self._saga_policy = None  # Lazy initialization
    
    def _saga_enabled(self) -> bool:
        """
        Check if Saga is enabled via policy.
        
        â­ CAPABILITY BY DESIGN, OPTIONAL BY POLICY:
        - Saga capability is built into the architecture
        - Enabled/disabled via policy configuration
        - Default: disabled (no overhead)
        """
        import os
        saga_enabled = os.getenv("SAGA_ENABLED", "false").lower() == "true"
        
        # Also check if specific operations should use Saga
        saga_operations = os.getenv("SAGA_OPERATIONS", "data_ingest_pipeline,data_mapping").split(",")
        
        # Store policy for later use
        if not hasattr(self, '_saga_policy') or self._saga_policy is None:
            self._saga_policy = {
                "enable_saga": saga_enabled,
                "saga_operations": [op.strip() for op in saga_operations],
                "compensation_handlers": self._get_compensation_handlers()
            }
        
        return self._saga_policy.get("enable_saga", False)
    
    def _get_compensation_handlers(self) -> Dict[str, Dict[str, str]]:
        """
        Get compensation handlers for this orchestrator's operations.
        
        Returns:
            Dict mapping operation -> milestone -> compensation_handler
        """
        return {
            "data_ingest_pipeline": {
                "ingest": "delete_uploaded_file",
                "parse": "mark_file_as_unparsed",
                "embed": "delete_embeddings",
                "expose": "remove_from_semantic_layer"
            },
            "data_mapping": {
                "analyze_source": "revert_source_analysis",
                "analyze_target": "revert_target_analysis",
                "generate_mapping": "delete_mapping_rules",
                "apply_mapping": "revert_transformation",
                "validate": "mark_as_invalid"
            }
        }
    
    async def _get_saga_journey_orchestrator(self):
        """Lazy initialization of Saga Journey Orchestrator."""
        if not hasattr(self, '_saga_orchestrator') or self._saga_orchestrator is None:
            try:
                curator = self.di_container.curator if hasattr(self.di_container, 'curator') else None
                if curator:
                    self._saga_orchestrator = await curator.discover_service_by_name("SagaJourneyOrchestratorService")
                    if self._saga_orchestrator:
                        self.logger.info("âœ… Discovered SagaJourneyOrchestratorService")
            except Exception as e:
                self.logger.warning(f"âš ï¸ SagaJourneyOrchestratorService not available: {e}")
                self._saga_orchestrator = None
        
        return self._saga_orchestrator
    
    async def _execute_with_saga(
        self,
        operation: str,
        workflow_func: Callable,
        milestones: List[str],
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute workflow with Saga guarantees if enabled by policy.
        
        Pattern: "Capability by Design, Optional by Policy"
        
        Args:
            operation: Operation name (e.g., "data_ingest_pipeline")
            workflow_func: Async function that executes the workflow
            milestones: List of milestone names for this operation
            user_context: Optional user context
        
        Returns:
            Dict with workflow result, including saga_id if Saga was used
        """
        if not self._saga_enabled():
            # Execute without Saga (normal flow)
            return await workflow_func()
        
        if operation not in self._saga_policy.get("saga_operations", []):
            # Execute without Saga (operation not in policy)
            return await workflow_func()
        
        # Get Saga Journey Orchestrator
        saga_orchestrator = await self._get_saga_journey_orchestrator()
        if not saga_orchestrator:
            self.logger.warning("âš ï¸ Saga Journey Orchestrator not available, executing without Saga")
            return await workflow_func()
        
        # Get compensation handlers for this operation
        compensation_handlers = self._saga_policy.get("compensation_handlers", {}).get(operation, {})
        
        # Design Saga journey
        saga_journey = await saga_orchestrator.design_saga_journey(
            journey_type=operation,
            requirements={
                "operation": operation,
                "milestones": milestones
            },
            compensation_handlers=compensation_handlers,
            user_context=user_context
        )
        
        if not saga_journey.get("success"):
            self.logger.warning(f"âš ï¸ Saga journey design failed: {saga_journey.get('error')}, executing without Saga")
            return await workflow_func()
        
        # Execute Saga journey
        saga_execution = await saga_orchestrator.execute_saga_journey(
            journey_id=saga_journey["journey_id"],
            user_id=user_context.get("user_id") if user_context else "anonymous",
            context={"operation": operation},
            user_context=user_context
        )
        
        if not saga_execution.get("success"):
            self.logger.warning(f"âš ï¸ Saga execution start failed: {saga_execution.get('error')}, executing without Saga")
            return await workflow_func()
        
        saga_id = saga_execution["saga_id"]
        
        # Execute workflow as Saga milestone
        try:
            result = await workflow_func()
            
            # Advance Saga step (success)
            await saga_orchestrator.advance_saga_step(
                saga_id=saga_id,
                journey_id=saga_journey["journey_id"],
                user_id=user_context.get("user_id") if user_context else "anonymous",
                step_result={"status": "complete", **result},
                user_context=user_context
            )
            
            result["saga_id"] = saga_id
            return result
            
        except Exception as e:
            # Advance Saga step (failure) - triggers automatic compensation
            await saga_orchestrator.advance_saga_step(
                saga_id=saga_id,
                journey_id=saga_journey["journey_id"],
                user_id=user_context.get("user_id") if user_context else "anonymous",
                step_result={"status": "failed", "error": str(e)},
                user_context=user_context
            )
            raise
```

#### 1.2 Integrate Saga into Orchestrate Methods

**Example: Data Ingestion Pipeline**

```python
async def orchestrate_data_ingest(
    self,
    file_data: bytes,
    file_name: str,
    file_type: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Orchestrate data ingestion with optional Saga guarantees.
    
    Pattern: "Capability by Design, Optional by Policy"
    """
    # Define milestones for this operation
    milestones = ["ingest", "parse", "embed", "expose"]
    
    # Execute with Saga if enabled
    return await self._execute_with_saga(
        operation="data_ingest_pipeline",
        workflow_func=lambda: self._execute_data_ingest_pipeline(
            file_data=file_data,
            file_name=file_name,
            file_type=file_type,
            user_context=user_context
        ),
        milestones=milestones,
        user_context=user_context
    )

async def _execute_data_ingest_pipeline(
    self,
    file_data: bytes,
    file_name: str,
    file_type: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Execute data ingestion pipeline (called by Saga or directly).
    
    This is the actual workflow implementation, extracted for reuse.
    """
    # Step 1: Orchestrate platform correlation
    correlation_context = await self._orchestrate_platform_correlation(
        operation="data_ingest",
        user_context=user_context
    )
    
    # Step 2: Execute ingest
    # ... existing logic ...
    
    # Step 3: Execute parse
    # ... existing logic ...
    
    # Step 4: Execute embed
    # ... existing logic ...
    
    # Step 5: Execute expose
    # ... existing logic ...
    
    return result
```

### 2. Compensation Handler Implementation

#### 2.1 Create Compensation Handler Service

**Location:** `backend/journey/services/compensation_handler_service/compensation_handler_service.py`

**Purpose:** Centralized service for executing compensation handlers

**Implementation:**
```python
class CompensationHandlerService(RealmServiceBase):
    """
    Compensation Handler Service - Executes compensation operations.
    
    WHAT: Provides compensation handlers for Saga rollback
    HOW: Domain-specific undo operations for each milestone type
    """
    
    async def execute_compensation(
        self,
        handler_name: str,
        milestone_data: Dict[str, Any],
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute a compensation handler.
        
        Args:
            handler_name: Name of compensation handler (e.g., "delete_uploaded_file")
            milestone_data: Data from the milestone that needs compensation
            user_context: Optional user context
        
        Returns:
            Dict with compensation result
        """
        # Route to appropriate handler
        if handler_name == "delete_uploaded_file":
            return await self._delete_uploaded_file(milestone_data, user_context)
        elif handler_name == "mark_file_as_unparsed":
            return await self._mark_file_as_unparsed(milestone_data, user_context)
        elif handler_name == "delete_embeddings":
            return await self._delete_embeddings(milestone_data, user_context)
        # ... more handlers ...
        else:
            return {
                "success": False,
                "error": f"Unknown compensation handler: {handler_name}"
            }
    
    async def _delete_uploaded_file(
        self,
        milestone_data: Dict[str, Any],
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Compensation: Delete uploaded file."""
        file_id = milestone_data.get("file_id")
        if not file_id:
            return {"success": False, "error": "file_id required"}
        
        # Get Content Steward or Librarian to delete file
        librarian = await self.get_librarian_api()
        if librarian:
            try:
                await librarian.delete_document(file_id, user_context=user_context)
                return {"success": True, "message": f"File {file_id} deleted"}
            except Exception as e:
                return {"success": False, "error": str(e)}
        
        return {"success": False, "error": "Librarian not available"}
    
    # ... more compensation handlers ...
```

#### 2.2 Register Compensation Handlers with Saga Orchestrator

**Location:** Saga Journey Orchestrator Service

**Changes:**
- Update `execute_compensation` to call `CompensationHandlerService`
- Ensure compensation handlers are idempotent

### 3. Policy Configuration Service

#### 3.1 Create Policy Configuration Service

**Location:** `backend/solution/services/policy_configuration_service/policy_configuration_service.py`

**Purpose:** Centralized policy management for WAL and Saga

**Implementation:**
```python
class PolicyConfigurationService(RealmServiceBase):
    """
    Policy Configuration Service - Manages WAL and Saga policies.
    
    WHAT: Centralized policy management
    HOW: Environment variables, configuration files, or API
    """
    
    async def get_wal_policy(
        self,
        orchestrator_name: str,
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Get WAL policy for an orchestrator."""
        # Check environment variables
        # Check configuration files
        # Check user-specific policies
        # Return policy dict
        pass
    
    async def get_saga_policy(
        self,
        orchestrator_name: str,
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Get Saga policy for an orchestrator."""
        # Check environment variables
        # Check configuration files
        # Check user-specific policies
        # Return policy dict
        pass
```

### 4. Journey Orchestrator Changes

#### 4.1 Add Saga Support to Journey Orchestrators

**Location:** Journey Orchestrators (Content, Insights, Operations, Business Outcomes)

**Changes:**
- Add `_execute_with_saga()` helper method (similar to Solution Orchestrators)
- Integrate Saga into multi-step workflows
- Define milestones for each workflow

**Example:**
```python
class ContentJourneyOrchestrator(OrchestratorBase):
    async def _execute_with_saga(
        self,
        operation: str,
        workflow_func: Callable,
        milestones: List[str],
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Execute workflow with Saga if enabled."""
        # Similar to Solution Orchestrator pattern
        pass
```

---

## ğŸ“‹ Implementation Phases

### Phase 1: Foundation (Week 1)

**Goal:** Set up Saga infrastructure

**Tasks:**
1. âœ… Create `CompensationHandlerService`
2. âœ… Register compensation handlers for all critical operations
3. âœ… Create `PolicyConfigurationService`
4. âœ… Update Saga Journey Orchestrator to use `CompensationHandlerService`
5. âœ… Add unit tests for compensation handlers

**Deliverables:**
- `CompensationHandlerService` implemented
- `PolicyConfigurationService` implemented
- Compensation handlers for all critical operations
- Unit tests passing

### Phase 2: Solution Orchestrator Integration (Week 2)

**Goal:** Integrate Saga into Solution Orchestrators

**Tasks:**
1. âœ… Add `_saga_enabled()` to all Solution Orchestrators
2. âœ… Add `_get_saga_journey_orchestrator()` to all Solution Orchestrators
3. âœ… Add `_execute_with_saga()` to all Solution Orchestrators
4. âœ… Integrate Saga into `DataSolutionOrchestratorService.orchestrate_data_ingest()`
5. âœ… Integrate Saga into `InsightsSolutionOrchestratorService.orchestrate_insights_mapping()`
6. âœ… Integrate Saga into `OperationsSolutionOrchestratorService.orchestrate_operations_workflow_generation()`
7. âœ… Integrate Saga into `BusinessOutcomesSolutionOrchestratorService.orchestrate_pillar_summaries_compilation()`

**Deliverables:**
- All Solution Orchestrators have Saga capability
- Critical operations integrated with Saga
- Integration tests passing

### Phase 3: Journey Orchestrator Integration (Week 3)

**Goal:** Integrate Saga into Journey Orchestrators

**Tasks:**
1. âœ… Add `_execute_with_saga()` to Journey Orchestrators
2. âœ… Integrate Saga into multi-step workflows
3. âœ… Define milestones for each workflow
4. âœ… Add compensation handlers for Journey-level operations

**Deliverables:**
- All Journey Orchestrators have Saga capability
- Multi-step workflows integrated with Saga
- Integration tests passing

### Phase 4: Policy Configuration (Week 4)

**Goal:** Make Saga policy-driven

**Tasks:**
1. âœ… Integrate `PolicyConfigurationService` into Solution Orchestrators
2. âœ… Add environment variable support
3. âœ… Add configuration file support
4. âœ… Add API for policy management
5. âœ… Document policy configuration

**Deliverables:**
- Policy-driven Saga enablement
- Configuration documentation
- Policy management API

### Phase 5: Testing & Validation (Week 5)

**Goal:** Comprehensive testing and validation

**Tasks:**
1. âœ… Unit tests for all compensation handlers
2. âœ… Integration tests for Saga workflows
3. âœ… E2E tests for critical operations with Saga
4. âœ… Failure scenario testing (compensation execution)
5. âœ… Performance testing (Saga overhead)
6. âœ… Policy configuration testing

**Deliverables:**
- Comprehensive test coverage
- Performance benchmarks
- Test documentation

---

## ğŸ§ª Testing Strategy

### Unit Tests

**Files to Create:**
- `tests/unit/journey/test_compensation_handler_service.py`
- `tests/unit/solution/test_saga_integration_data.py`
- `tests/unit/solution/test_saga_integration_insights.py`
- `tests/unit/solution/test_saga_integration_operations.py`
- `tests/unit/solution/test_saga_integration_business_outcomes.py`

**Test Cases:**
- Compensation handler execution
- Saga policy enablement/disablement
- Saga journey design
- Saga execution flow
- Compensation execution on failure

### Integration Tests

**Files to Create:**
- `tests/integration/saga/test_data_ingest_pipeline_saga.py`
- `tests/integration/saga/test_data_mapping_saga.py`
- `tests/integration/saga/test_operations_workflow_generation_saga.py`
- `tests/integration/saga/test_business_outcomes_roadmap_saga.py`

**Test Cases:**
- Full Saga workflow execution
- Failure scenarios with compensation
- Policy-driven enablement/disablement
- Multi-step workflow compensation

### E2E Tests

**Files to Create:**
- `tests/e2e/saga/test_data_pipeline_saga_e2e.py`
- `tests/e2e/saga/test_operations_workflow_saga_e2e.py`
- `tests/e2e/saga/test_business_outcomes_saga_e2e.py`

**Test Cases:**
- End-to-end Saga workflows
- Failure and compensation scenarios
- Policy configuration impact

---

## ğŸ“Š Policy Examples

### Policy 1: Saga Enabled for Critical Operations

```python
saga_policy = {
    "enable_saga": True,
    "saga_operations": [
        "data_ingest_pipeline",
        "data_mapping",
        "operations_workflow_generation",
        "operations_coexistence_analysis",
        "pillar_summaries_compilation",
        "roadmap_generation",
        "poc_proposal_generation"
    ],
    "compensation_handlers": {
        # ... defined per operation ...
    }
}
```

**Use Case:** Production environment requiring atomicity guarantees

### Policy 2: Saga Disabled (Default)

```python
saga_policy = {
    "enable_saga": False,
    "saga_operations": [],
    "compensation_handlers": {}
}
```

**Use Case:** Development environment, simple operations

### Policy 3: Saga Enabled for Specific Operations

```python
saga_policy = {
    "enable_saga": True,
    "saga_operations": [
        "data_ingest_pipeline",
        "operations_workflow_generation"
    ],
    "compensation_handlers": {
        # ... only for enabled operations ...
    }
}
```

**Use Case:** Selective Saga enablement for high-risk operations

---

## ğŸ” Additional Platform Changes

### 1. Event System Integration

**Changes:**
- Ensure Post Office events trigger Saga milestone progression
- Add Saga-specific event types
- Integrate Saga state changes with event system

### 2. Monitoring & Observability

**Changes:**
- Add Saga metrics to Nurse (telemetry)
- Track Saga execution times
- Monitor compensation execution
- Alert on Saga failures

### 3. Documentation

**Files to Create/Update:**
- `docs/SAGA_INTEGRATION_GUIDE.md` - User guide
- `docs/SAGA_COMPENSATION_HANDLERS.md` - Handler reference
- `docs/SAGA_POLICY_CONFIGURATION.md` - Policy guide
- Update `PLATFORM_ARCHITECTURAL_ROADMAP.md` with Saga status

---

## âœ… Success Criteria

### Functional Requirements
- âœ… Saga integrated into all critical operations
- âœ… Compensation handlers implemented for all milestones
- âœ… Policy-driven enablement/disablement working
- âœ… Failure scenarios trigger compensation correctly
- âœ… All tests passing

### Non-Functional Requirements
- âœ… Saga overhead < 5% when enabled
- âœ… Compensation execution time < 2x original operation
- âœ… Policy configuration changes take effect immediately
- âœ… No performance impact when Saga disabled

### Documentation Requirements
- âœ… Integration guide complete
- âœ… Compensation handler reference complete
- âœ… Policy configuration guide complete
- âœ… Architecture documentation updated

---

## ğŸ“š Related Documentation

- [WAL_SAGA_INTEGRATION_PLAN.md](./WAL_SAGA_INTEGRATION_PLAN.md) - Original WAL/Saga plan
- [SAGA_JOURNEY_ORCHESTRATOR.md](../../symphainy-platform/backend/journey/docs/SAGA_JOURNEY_ORCHESTRATOR.md) - Saga orchestrator guide
- [PLATFORM_ARCHITECTURAL_ROADMAP.md](./PLATFORM_ARCHITECTURAL_ROADMAP.md) - Main roadmap
- [distributed_transaction_management_saga_choreography.md](./distributed_transaction_management_saga_choreography.md) - Saga pattern overview

---

**Last Updated:** January 2025  
**Status:** ğŸ“‹ **DETAILED IMPLEMENTATION PLAN READY FOR EXECUTION**

**Next Steps:**
1. âœ… Review and approve plan
2. ğŸ“‹ Begin Phase 1 (Foundation)
3. ğŸ“‹ Track progress against phases
4. ğŸ“‹ Verify success criteria before production deployment




