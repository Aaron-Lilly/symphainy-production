# Business Enablement Vertical Slice Architecture Design
## ContentAnalysisOrchestrator Complete Rebuild

**Date:** December 11, 2025  
**Status:** üé® Design Phase  
**Purpose:** Complete architecture design for vertical slice implementation

---

## üéØ **Design Overview**

This document defines the complete architecture for the ContentAnalysisOrchestrator vertical slice, covering:
1. **Orchestrator Design** - DIL SDK integration, service orchestration, workflow_id propagation
2. **Enabling Services Design** - FileParserService, ContentMetadataExtractionService, EmbeddingService
3. **Agents Design** - Lightweight MVP agentic forward pattern
4. **MCP Server Design** - Read-only tools with agent commentary

**Key Principles:**
- ‚úÖ **Preserve all functionality** - Binary + copybook, all file types
- ‚úÖ **Lightweight MVP** - Agents provide commentary only (no editing)
- ‚úÖ **Gap-focused** - Address existing issues vs new features
- ‚úÖ **DIL SDK integration** - All Smart City operations via DIL SDK

---

## 1. Orchestrator Design

### 1.1 Architecture Pattern

**Base Class:** `OrchestratorBase` (extends `RealmServiceBase`)

**Key Components:**
- DIL SDK integration
- Service orchestration
- Workflow_id propagation
- Agent integration
- MCP server integration

### 1.2 Class Structure

```python
from bases.orchestrator_base import OrchestratorBase
from backend.smart_city.sdk.dil_sdk import DILSDK

class ContentAnalysisOrchestrator(OrchestratorBase):
    """
    Content Analysis Orchestrator - Content Pillar Only
    
    WHAT: I orchestrate content processing (parsing, metadata, embeddings)
    HOW: I coordinate FileParserService, ContentMetadataExtractionService, EmbeddingService
    """
    
    def __init__(self, business_orchestrator: Any):
        super().__init__(
            service_name="ContentAnalysisOrchestratorService",
            realm_name=business_orchestrator.realm_name,
            platform_gateway=business_orchestrator.platform_gateway,
            di_container=business_orchestrator.di_container
        )
        self.business_orchestrator = business_orchestrator
        self.dil_sdk: Optional[DILSDK] = None
        self.file_parser_service: Optional[FileParserService] = None
        self.content_metadata_service: Optional[ContentMetadataExtractionService] = None
        self.embedding_service: Optional[EmbeddingService] = None
        self.content_liaison_agent: Optional[ContentLiaisonAgent] = None
        self.content_processing_agent: Optional[ContentProcessingAgent] = None
        self.mcp_server: Optional[ContentAnalysisMCPServer] = None
    
    async def initialize(self) -> bool:
        """Initialize orchestrator with DIL SDK and services."""
        await super().initialize()
        
        # 1. Get Smart City services
        content_steward = await self.get_content_steward_api()
        librarian = await self.get_librarian_api()
        data_steward = await self.get_data_steward_api()
        nurse = await self.get_nurse_api()
        
        # 2. Initialize DIL SDK
        smart_city_services = {
            "content_steward": content_steward,
            "librarian": librarian,
            "data_steward": data_steward,
            "nurse": nurse
        }
        self.dil_sdk = DILSDK(smart_city_services, logger=self.logger)
        
        # 3. Initialize enabling services
        self.file_parser_service = await self._initialize_file_parser_service()
        self.content_metadata_service = await self._initialize_content_metadata_service()
        self.embedding_service = await self._initialize_embedding_service()
        
        # 4. Initialize agents
        self.content_liaison_agent = await self._initialize_content_liaison_agent()
        self.content_processing_agent = await self._initialize_content_processing_agent()
        
        # 5. Initialize MCP server
        self.mcp_server = await self._initialize_mcp_server()
        
        return True
```

### 1.3 DIL SDK Integration Pattern

**All Smart City operations go through DIL SDK:**

```python
# Upload file
upload_result = await self.dil_sdk.upload_file(
    file_data=file_data,
    file_name=file_name,
    file_type=file_type,
    metadata=metadata,
    workflow_id=workflow_id,
    user_context=user_context
)

# Store parsed file
store_result = await self.dil_sdk.store_parsed_file(
    file_id=file_id,
    parsed_data=parsed_data,
    format_type="json_structured",  # or "json_chunks", "parquet"
    content_type="structured",  # or "unstructured", "hybrid"
    workflow_id=workflow_id,
    user_context=user_context
)

# Store content metadata
metadata_result = await self.dil_sdk.store_content_metadata(
    file_id=file_id,
    content_metadata=metadata_dict,
    workflow_id=workflow_id,
    user_context=user_context
)

# Store embeddings
embeddings_result = await self.dil_sdk.store_semantic_embeddings(
    content_id=content_id,
    file_id=file_id,
    embeddings=embeddings_list,
    workflow_id=workflow_id,
    user_context=user_context
)

# Track lineage
lineage_result = await self.dil_sdk.track_lineage(
    source_id=source_id,
    target_id=target_id,
    relationship_type="parsed_from",
    workflow_id=workflow_id,
    user_context=user_context
)
```

### 1.4 Workflow ID Propagation

**Generate workflow_id at orchestrator entry point:**

```python
async def handle_content_upload(
    self,
    file_data: bytes,
    file_name: str,
    file_type: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Handle complete content upload workflow."""
    
    # Generate workflow_id for end-to-end tracking
    workflow_id = str(uuid.uuid4())
    
    # Propagate workflow_id to all operations
    upload_result = await self.dil_sdk.upload_file(
        file_data=file_data,
        file_name=file_name,
        file_type=file_type,
        workflow_id=workflow_id,
        user_context=user_context
    )
    
    # Continue workflow with same workflow_id
    parse_result = await self.parse_content(
        file_id=upload_result["file_id"],
        workflow_id=workflow_id,
        user_context=user_context
    )
    
    # ... rest of workflow
```

### 1.5 Service Orchestration Pattern

**Orchestrator coordinates services, services use DIL SDK:**

```python
async def parse_content(
    self,
    file_id: str,
    workflow_id: Optional[str] = None,
    parse_options: Optional[Dict[str, Any]] = None,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Parse content via FileParserService."""
    
    # 1. Service performs parsing
    parse_result = await self.file_parser_service.parse_file(
        file_id=file_id,
        parse_options=parse_options,
        user_context=user_context
    )
    
    # 2. Service stores parsed file via DIL SDK (internal to service)
    # FileParserService internally calls: await self.dil_sdk.store_parsed_file(...)
    
    # 3. Return result
    return parse_result
```

### 1.6 Error Handling Pattern

```python
async def handle_content_upload(...):
    try:
        # Generate workflow_id
        workflow_id = str(uuid.uuid4())
        
        # Upload file
        upload_result = await self.dil_sdk.upload_file(...)
        
        # Parse file
        parse_result = await self.parse_content(...)
        
        # Extract metadata
        metadata_result = await self.extract_content_metadata(...)
        
        # Create embeddings
        embeddings_result = await self.create_embeddings(...)
        
        return {
            "success": True,
            "workflow_id": workflow_id,
            "file_id": upload_result["file_id"],
            "parsed_file_id": parse_result.get("parsed_file_id"),
            "metadata_id": metadata_result.get("metadata_id"),
            "embeddings_id": embeddings_result.get("embeddings_id")
        }
    
    except Exception as e:
        self.logger.error(f"Content upload failed: {e}", exc_info=True)
        
        # Record error via DIL SDK
        await self.dil_sdk.record_platform_event(
            event_type="content_upload_failed",
            event_data={"error": str(e), "workflow_id": workflow_id},
            user_context=user_context
        )
        
        return {
            "success": False,
            "error": str(e),
            "workflow_id": workflow_id
        }
```

### 1.7 Key Methods

```python
# Main workflow
async def handle_content_upload(...) -> Dict[str, Any]
async def parse_content(...) -> Dict[str, Any]
async def extract_content_metadata(...) -> Dict[str, Any]
async def create_embeddings(...) -> Dict[str, Any]

# Agent integration (lightweight MVP)
async def get_content_results_with_commentary(
    self,
    file_id: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Get content results with agent commentary."""
    
    # Get results
    results = await self._get_content_results(file_id)
    
    # Get agent commentary (lightweight MVP)
    commentary = await self.content_processing_agent.provide_commentary(
        results=results,
        user_context=user_context
    )
    
    return {
        "results": results,
        "commentary": commentary  # Light commentary only
    }
```

---

## 2. Enabling Services Design

### 2.1 FileParserService Architecture

**Purpose:** Parse files with parsing type determination

**Key Changes:**
- Add parsing type determination (structured/unstructured/hybrid/workflow/sop)
- Preserve binary + copybook support
- Module-based architecture

**Structure:**
```
FileParserService/
‚îú‚îÄ‚îÄ file_parser_service.py (main service)
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ initialization.py
‚îÇ   ‚îú‚îÄ‚îÄ file_retrieval.py
‚îÇ   ‚îú‚îÄ‚îÄ parsing_orchestrator.py (NEW - determines parsing type)
‚îÇ   ‚îú‚îÄ‚îÄ structured_parsing.py (NEW - includes binary + copybook)
‚îÇ   ‚îú‚îÄ‚îÄ unstructured_parsing.py (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_parsing.py (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ workflow_parsing.py (NEW - basic text extraction)
‚îÇ   ‚îú‚îÄ‚îÄ sop_parsing.py (NEW - basic text extraction)
‚îÇ   ‚îî‚îÄ‚îÄ utilities.py
```

**Parsing Type Determination:**
```python
async def _determine_parsing_type(
    self,
    file_id: str,
    file_type: str,
    parse_options: Optional[Dict[str, Any]] = None
) -> str:
    """
    Determine parsing type: structured, unstructured, hybrid, workflow, sop
    
    Rule-based (from frontend file type selection):
    - structured: xlsx, csv, json, bin (binary with copybook)
    - unstructured: pdf, docx, txt
    - hybrid: excel_with_text
    - workflow: json, bpmn, drawio
    - sop: docx, pdf, txt, md
    """
    # Check parse_options for explicit type
    if parse_options and "parsing_type" in parse_options:
        return parse_options["parsing_type"]
    
    # Rule-based determination
    structured_types = ["xlsx", "csv", "json", "bin"]
    unstructured_types = ["pdf", "docx", "txt"]
    hybrid_types = ["excel_with_text"]
    workflow_types = ["bpmn", "drawio"]
    sop_types = ["md"]
    
    if file_type in structured_types:
        return "structured"
    elif file_type in unstructured_types:
        return "unstructured"
    elif file_type in hybrid_types:
        return "hybrid"
    elif file_type in workflow_types or (file_type == "json" and parse_options and parse_options.get("is_workflow")):
        return "workflow"
    elif file_type in sop_types or (file_type in ["docx", "pdf", "txt"] and parse_options and parse_options.get("is_sop")):
        return "sop"
    else:
        return "unstructured"  # Default
```

**Binary + Copybook Support (in structured_parsing.py):**
```python
async def parse_structured_file(
    self,
    file_data: bytes,
    file_type: str,
    parse_options: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Parse structured file (including binary with copybook)."""
    
    # Handle binary files with copybook
    if file_type in ["bin", "binary"]:
        copybook = None
        copybook_path = None
        
        if parse_options:
            copybook = parse_options.get("copybook")  # String
            copybook_path = parse_options.get("copybook_path")  # File path
        
        if not copybook and not copybook_path:
            return {
                "success": False,
                "error": "Copybook required for binary file parsing. Provide 'copybook' (string) or 'copybook_path' (file path) in options."
            }
        
        # Use MainframeProcessingAbstraction
        abstraction = self.platform_gateway.get_abstraction(
            realm_name=self.realm_name,
            abstraction_name="MainframeProcessingAbstraction"
        )
        
        # Create FileParsingRequest
        request = FileParsingRequest(
            file_data=file_data,
            filename=filename,
            options=parse_options
        )
        
        result = await abstraction.parse_file(request)
        return result
    
    # Handle other structured types (Excel, CSV, JSON)
    # ... existing logic
```

**DIL SDK Integration (internal to service):**
```python
# In FileParserService.parse_file()
async def parse_file(...):
    # 1. Parse file
    parse_result = await self._parse_file_internal(...)
    
    # 2. Store parsed file via DIL SDK
    if parse_result["success"]:
        store_result = await self.dil_sdk.store_parsed_file(
            file_id=file_id,
            parsed_data=parse_result["data"],
            format_type="json_structured",  # or "json_chunks" for unstructured
            content_type=parsing_type,  # "structured", "unstructured", "hybrid"
            workflow_id=workflow_id,
            user_context=user_context
        )
        parse_result["parsed_file_id"] = store_result["file_id"]
    
    return parse_result
```

### 2.2 ContentMetadataExtractionService Architecture

**Purpose:** Extract content metadata and store via DIL SDK

**Structure:**
```
ContentMetadataExtractionService/
‚îú‚îÄ‚îÄ content_metadata_extraction_service.py (main service)
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ initialization.py
‚îÇ   ‚îú‚îÄ‚îÄ metadata_extraction.py
‚îÇ   ‚îî‚îÄ‚îÄ utilities.py
```

**Key Methods:**
```python
async def extract_and_store_metadata(
    self,
    file_id: str,
    parsed_file_id: str,
    parse_result: Dict[str, Any],
    workflow_id: Optional[str] = None,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Extract content metadata from parsed file and store via DIL SDK.
    
    Extracts:
    - Schema (structure)
    - Columns (column names)
    - Row count
    - Column count
    - Data types
    - Parsing method
    - File type
    - Original filename
    
    Stores via DIL SDK ‚Üí Librarian.store_content_metadata()
    """
    # 1. Extract metadata
    metadata = await self._extract_metadata(parse_result)
    
    # 2. Store via DIL SDK
    store_result = await self.dil_sdk.store_content_metadata(
        file_id=file_id,
        content_metadata=metadata,
        workflow_id=workflow_id,
        user_context=user_context
    )
    
    return {
        "success": True,
        "metadata_id": store_result["metadata_id"],
        "metadata": metadata
    }
```

### 2.3 EmbeddingService Architecture

**Purpose:** Create semantic embeddings and store via DIL SDK

**Structure:**
```
EmbeddingService/
‚îú‚îÄ‚îÄ embedding_service.py (main service)
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ initialization.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding_creation.py
‚îÇ   ‚îî‚îÄ‚îÄ utilities.py
```

**Key Methods:**
```python
async def create_and_store_embeddings(
    self,
    file_id: str,
    parsed_file_id: str,
    content_data: Any,
    workflow_id: Optional[str] = None,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Create semantic embeddings from content and store via DIL SDK.
    
    Uses StatelessHFInferenceAgent for embedding generation.
    Creates both metadata embeddings and meaning embeddings.
    
    Stores via DIL SDK ‚Üí Librarian.store_embeddings()
    """
    # 1. Generate embeddings via StatelessHFInferenceAgent
    embeddings = await self._generate_embeddings(content_data)
    
    # 2. Store via DIL SDK
    store_result = await self.dil_sdk.store_semantic_embeddings(
        content_id=parsed_file_id,
        file_id=file_id,
        embeddings=embeddings,
        workflow_id=workflow_id,
        user_context=user_context
    )
    
    return {
        "success": True,
        "embeddings_id": store_result["embeddings_id"],
        "embeddings_count": len(embeddings)
    }
```

---

## 3. Agents Design (Lightweight MVP)

### 3.1 Agentic Forward Pattern (Lightweight MVP)

**Key Principle:** Agents provide **light commentary** on results, not editing/modification

**Pattern:**
```
Service executes ‚Üí Returns results ‚Üí Agent provides commentary ‚Üí Return to user
```

**NOT:**
```
Agent executes ‚Üí Agent modifies ‚Üí Agent returns modified results
```

### 3.2 ContentProcessingAgent Architecture

**Purpose:** Provide light commentary on content processing results

**Key Methods:**
```python
async def provide_commentary(
    self,
    results: Dict[str, Any],
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Provide light commentary on content processing results.
    
    Lightweight MVP - commentary only, no editing.
    """
    # Analyze results
    commentary = await self._analyze_results(results)
    
    return {
        "commentary": commentary,  # Light commentary text
        "insights": self._extract_insights(results),  # Read-only insights
        "summary": self._summarize_results(results)  # Summary
    }

async def explain_parsing_result(
    self,
    parse_result: Dict[str, Any],
    user_context: Optional[Dict[str, Any]] = None
) -> str:
    """Explain parsing result in user-friendly way."""
    # Light commentary on parsing result
    return f"Parsed {parse_result.get('row_count', 0)} rows with {parse_result.get('column_count', 0)} columns."

async def explain_metadata(
    self,
    metadata: Dict[str, Any],
    user_context: Optional[Dict[str, Any]] = None
) -> str:
    """Explain metadata in user-friendly way."""
    # Light commentary on metadata
    return f"Extracted metadata: {len(metadata.get('columns', []))} columns identified."
```

### 3.3 ContentLiaisonAgent Architecture

**Purpose:** Provide conversational guidance and light commentary

**Key Methods:**
```python
async def chat(
    self,
    message: str,
    session_id: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Provide conversational guidance with light commentary.
    
    Lightweight MVP - guidance + commentary, no editing.
    """
    # Analyze intent
    intent = await self._analyze_intent(message)
    
    # Route to appropriate handler
    if intent == "get_results":
        results = await self._get_results(session_id)
        commentary = await self.content_processing_agent.provide_commentary(results)
        return {
            "response": commentary["commentary"],
            "results": results
        }
    elif intent == "explain_file":
        # Provide explanation with commentary
        explanation = await self._explain_file(message, session_id)
        return {"response": explanation}
    else:
        # General guidance
        return {"response": await self._provide_guidance(message)}
```

### 3.4 Agent Integration Pattern

**Orchestrator uses agents for commentary:**

```python
# In ContentAnalysisOrchestrator
async def get_content_results_with_commentary(
    self,
    file_id: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Get results with agent commentary."""
    
    # 1. Get results (no agent involvement)
    results = await self._get_content_results(file_id)
    
    # 2. Get agent commentary (lightweight MVP)
    commentary = await self.content_processing_agent.provide_commentary(
        results=results,
        user_context=user_context
    )
    
    # 3. Return results + commentary (read-only)
    return {
        "results": results,  # Original results
        "commentary": commentary  # Light commentary
    }
```

---

## 4. MCP Server Design (Lightweight MVP)

### 4.1 Tool Design Pattern

**Key Principle:** Tools orchestrate services + agents, return read-only results + commentary

**Tool Structure:**
```python
@tool
async def handle_content_upload_tool(
    file_data: bytes,
    file_name: str,
    file_type: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Upload file ‚Üí Parse ‚Üí Metadata ‚Üí Embeddings
    
    Returns results with light agent commentary.
    """
    # 1. Orchestrate via orchestrator
    result = await orchestrator.handle_content_upload(
        file_data=file_data,
        file_name=file_name,
        file_type=file_type,
        user_context=user_context
    )
    
    # 2. Get agent commentary
    commentary = await orchestrator.content_processing_agent.provide_commentary(
        results=result,
        user_context=user_context
    )
    
    # 3. Return results + commentary (read-only)
    return {
        "success": result["success"],
        "file_id": result.get("file_id"),
        "workflow_id": result.get("workflow_id"),
        "commentary": commentary  # Light commentary
    }
```

### 4.2 Key Tools

```python
# Use case-level tools (not low-level service tools)
- handle_content_upload_tool: Upload ‚Üí Parse ‚Üí Metadata ‚Üí Embeddings (with commentary)
- parse_file_tool: Parse file (with commentary)
- extract_metadata_tool: Extract metadata (with commentary)
- create_embeddings_tool: Create embeddings (with commentary)
- get_content_results_tool: Get results with commentary (read-only)
```

### 4.3 Tool Handler Pattern

```python
class ContentAnalysisMCPServer:
    def __init__(self, orchestrator: ContentAnalysisOrchestrator):
        self.orchestrator = orchestrator
        self.tools = [
            self.handle_content_upload_tool,
            self.parse_file_tool,
            self.extract_metadata_tool,
            self.create_embeddings_tool,
            self.get_content_results_tool
        ]
    
    @tool
    async def handle_content_upload_tool(...):
        """Tool handler - orchestrates services + agents."""
        # Orchestrate
        result = await self.orchestrator.handle_content_upload(...)
        
        # Get commentary
        commentary = await self.orchestrator.content_processing_agent.provide_commentary(result)
        
        # Return read-only results + commentary
        return {"results": result, "commentary": commentary}
```

---

## 5. Integration Contracts

### 5.1 Service Contracts

**FileParserService Contract:**
```python
async def parse_file(
    file_id: str,
    parse_options: Optional[Dict[str, Any]] = None,
    workflow_id: Optional[str] = None,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Returns:
    {
        "success": bool,
        "parsed_file_id": str,  # Stored via DIL SDK
        "parsing_type": str,  # "structured", "unstructured", "hybrid", "workflow", "sop"
        "data": Any,  # Parsed data
        "metadata": Dict[str, Any]
    }
    """
```

**ContentMetadataExtractionService Contract:**
```python
async def extract_and_store_metadata(
    file_id: str,
    parsed_file_id: str,
    parse_result: Dict[str, Any],
    workflow_id: Optional[str] = None,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Returns:
    {
        "success": bool,
        "metadata_id": str,  # Stored via DIL SDK
        "metadata": Dict[str, Any]
    }
    """
```

**EmbeddingService Contract:**
```python
async def create_and_store_embeddings(
    file_id: str,
    parsed_file_id: str,
    content_data: Any,
    workflow_id: Optional[str] = None,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Returns:
    {
        "success": bool,
        "embeddings_id": str,  # Stored via DIL SDK
        "embeddings_count": int
    }
    """
```

### 5.2 Agent Contracts

**ContentProcessingAgent Contract:**
```python
async def provide_commentary(
    results: Dict[str, Any],
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Returns:
    {
        "commentary": str,  # Light commentary text
        "insights": List[str],  # Read-only insights
        "summary": str  # Summary
    }
    """
```

**ContentLiaisonAgent Contract:**
```python
async def chat(
    message: str,
    session_id: str,
    user_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Returns:
    {
        "response": str,  # Guidance or commentary
        "results": Optional[Dict[str, Any]]  # If applicable
    }
    """
```

---

## 6. Gap Analysis

### 6.1 Identified Gaps (Content Pillar)

**Minimal functional gaps identified:**

1. **Agent Integration Gap**
   - ContentProcessingAgent exists but not used
   - Missing `set_orchestrator()` call
   - **Fix:** Integrate agent for commentary

2. **Result Presentation Gap**
   - Results not presented with commentary
   - **Fix:** Add commentary methods

3. **Tool Usage Gap**
   - MCP tools exist but not fully integrated
   - **Fix:** Complete tool integration

### 6.2 Gap Remediation Strategy

**Focus on addressing gaps vs adding new features:**

1. ‚úÖ Integrate ContentProcessingAgent for commentary
2. ‚úÖ Add result presentation with commentary
3. ‚úÖ Complete MCP tool integration
4. ‚ùå **NOT adding:** New agent capabilities, editing features, modification tools

---

## 7. Functionality Preservation Checklist

### 7.1 File Type Support

- [x] Excel (xlsx)
- [x] CSV
- [x] JSON
- [x] PDF
- [x] Word (docx)
- [x] Text (txt)
- [x] **Binary with copybook (bin)** ‚Üê Preserved
- [x] COBOL
- [x] Mainframe

### 7.2 Parsing Capabilities

- [x] Structured parsing
- [x] Unstructured parsing
- [x] Hybrid parsing
- [x] **Binary + copybook parsing** ‚Üê Preserved
- [x] Workflow parsing (basic text extraction)
- [x] SOP parsing (basic text extraction)

---

## 8. Design Validation

### 8.1 Architecture Validation

- [x] DIL SDK integration pattern defined
- [x] Service orchestration pattern defined
- [x] Workflow_id propagation pattern defined
- [x] Agent integration pattern defined (lightweight MVP)
- [x] MCP server pattern defined (lightweight MVP)
- [x] Error handling pattern defined
- [x] Service contracts defined
- [x] Agent contracts defined

### 8.2 Functionality Preservation

- [x] Binary + copybook support preserved
- [x] All file types supported
- [x] All parsing capabilities preserved

### 8.3 Gap Analysis

- [x] Gaps identified
- [x] Remediation strategy defined
- [x] Focus on gaps vs new features

---

**Last Updated:** December 11, 2025  
**Status:** ‚úÖ Design Complete  
**Next Action:** Begin Phase 1 (Enabling Services Foundation)

