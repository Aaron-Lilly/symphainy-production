# Phase 3 TODO Deep Dive Analysis

**Date:** November 11, 2025  
**Purpose:** Detailed investigation of 4 critical TODOs identified in Phase 3

---

## üîç Executive Summary

After deep investigation, here's what we found:

1. **File Selection:** ‚úÖ **Source of Truth Found** - `ContentAPIManager.listFiles()` is the single source
2. **Visualization:** ‚ùå **CRITICAL ERROR** - We used **Vega-Lite** but platform uses **Recharts + Nivo**
3. **NLP Queries:** ‚ö†Ô∏è **PLACEHOLDER ONLY** - Backend has stub implementation, needs full architecture
4. **Export Reports:** ‚ÑπÔ∏è **CLARIFICATION NEEDED** - Placeholder in backend, needs requirements

---

## 1. File Selection - Single Source of Truth ‚úÖ

### **Finding: ContentAPIManager is the source of truth**

**Location:** `symphainy-frontend/shared/managers/ContentAPIManager.ts`

**Current Implementation:**
```typescript
// ContentAPIManager.listFiles() - Line 50
async listFiles(): Promise<ContentFile[]> {
  const response = await fetch(`${this.baseURL}/api/content-pillar/list-uploaded-files`, {
    headers: {
      'Authorization': `Bearer ${this.sessionToken}`,
      'Content-Type': 'application/json',
      'X-Session-Token': this.sessionToken
    }
  });
  
  const data = await response.json();
  return data.files || [];
}
```

**How FileDashboard Uses It:**
```typescript
// symphainy-frontend/app/pillars/content/components/FileDashboard.tsx
const loadFiles = useCallback(async () => {
  const sessionToken = guideSessionToken || 'debug-token';
  const apiManager = new ContentAPIManager(sessionToken);
  
  const contentFiles = await apiManager.listFiles();
  
  // Map ContentFile to FileMetadata format
  const mappedFiles: FileMetadata[] = contentFiles.map((cf) => ({
    uuid: cf.id,
    file_id: cf.id,
    ui_name: cf.name,
    file_type: cf.type,
    file_size: cf.size,
    uploaded_at: cf.uploadDate,
    // ... more mappings
  }));
  
  setFiles(mappedFiles);
}, [isAuthenticated]);
```

### **What We Need to Fix:**

**File:** `symphainy-frontend/app/pillars/insights/components/InsightsFileSelector.tsx`

**Current Problem (Lines 103-118):**
```typescript
// TODO: Load actual files from Content Pillar
<SelectItem value="file_placeholder_001">
  <div className="flex flex-col">
    <span className="font-medium">Sample File 1 (Placeholder)</span>
    <span className="text-xs text-gray-500">CSV - 1.2 MB</span>
  </div>
</SelectItem>
```

**Solution:**
```typescript
// Add state for files
const [files, setFiles] = useState<ContentFile[]>([]);

// Load files using ContentAPIManager
useEffect(() => {
  if (sourceMode === 'file') {
    loadFiles();
  }
}, [sourceMode]);

const loadFiles = async () => {
  try {
    setLoading(true);
    const sessionToken = guideSessionToken || 'debug-token';
    const apiManager = new ContentAPIManager(sessionToken);
    const contentFiles = await apiManager.listFiles();
    setFiles(contentFiles);
  } catch (err) {
    console.error('Error loading files:', err);
    setError('Failed to load files');
  } finally {
    setLoading(false);
  }
};

// Render actual files in select
<SelectContent>
  {files.map((file) => (
    <SelectItem key={file.id} value={file.id}>
      <div className="flex flex-col">
        <span className="font-medium">{file.name}</span>
        <span className="text-xs text-gray-500">
          {file.type} - {formatFileSize(file.size)}
        </span>
      </div>
    </SelectItem>
  ))}
</SelectContent>
```

**Action Required:** 
- Import `ContentAPIManager` and `useGlobalSession`
- Add file loading logic to `InsightsFileSelector`
- Remove placeholder files
- ~30 lines of code to add

---

## 2. Visualization Library - CRITICAL ERROR ‚ùå

### **Finding: Platform uses Recharts + Nivo, NOT Vega-Lite**

**Current Visualization Stack:**
```typescript
// symphainy-frontend/components/ui/chart.tsx - Lines 9-29
// The platform uses RECHARTS for standard charts
import { BarChart, LineChart, PieChart, AreaChart } from "recharts";

// And NIVO for advanced visualizations
import { ResponsiveBar } from "@nivo/bar";
import { ResponsiveLine } from "@nivo/line";
import { ResponsiveHeatMap } from "@nivo/heatmap";
import { ResponsiveScatterPlot } from "@nivo/scatterplot";
```

**Supported Chart Types:**
- **Recharts:** bar, line, pie, area
- **Nivo:** bar, line, heatmap, scatter

**Chart Config Interface:**
```typescript
interface ChartConfig {
  type: 'bar' | 'line' | 'pie' | 'area' | 'heatmap' | 'scatter';
  library?: 'recharts' | 'nivo';  // Defaults to 'recharts'
  title?: string;
  description?: string;
  xAxisKey?: string;
  yAxisKey?: string;
  dataKey?: string;
  colors?: string[];
  height?: number;
  showLegend?: boolean;
  showTooltip?: boolean;
  showGrid?: boolean;
  nivoConfig?: any;
  rechartsConfig?: any;
}
```

### **What We Need to Fix:**

**File:** `symphainy-frontend/app/pillars/insights/components/InsightsSummaryDisplay.tsx`

**Current Problem (Lines 141-149):**
```typescript
{/* Placeholder for Vega-Lite rendering */}
<div className="bg-gray-100 rounded p-8 text-center text-sm text-gray-500">
  <BarChart3 className="h-16 w-16 mx-auto mb-2 text-gray-400" />
  <p>Chart visualization ({viz.chart_type})</p>
  <p className="text-xs mt-2">Vega-Lite spec: {viz.visualization_id}</p>
  {/* TODO: Integrate actual Vega-Lite renderer */}
</div>
```

**Solution:**
```typescript
// Import the existing Chart component
import ChartComponent, { ChartConfig, ChartData } from '@/components/ui/chart';

// Transform backend visualization spec to ChartConfig
const transformVisualizationToChartConfig = (viz: any): { data: ChartData[], config: ChartConfig } => {
  // Backend sends vega_lite_spec, but we need to transform it to Recharts/Nivo format
  // OR backend should send recharts_spec instead
  
  return {
    data: viz.chart_data || [],  // Backend should provide this
    config: {
      type: viz.chart_type,  // 'bar', 'line', 'pie', etc.
      library: viz.library || 'recharts',
      title: viz.title,
      description: viz.rationale,
      xAxisKey: viz.x_axis_key || 'name',
      dataKey: viz.data_key || 'value',
      height: 300,
      showLegend: true,
      showTooltip: true,
      showGrid: true
    }
  };
};

// Render actual chart
{summary.visualizations!.map((viz, idx) => {
  const { data, config } = transformVisualizationToChartConfig(viz);
  
  return (
    <div key={viz.visualization_id} className="border border-gray-200 rounded-lg p-4 bg-white">
      <ChartComponent data={data} config={config} />
    </div>
  );
})}
```

**Backend Changes Required:**

**File:** `symphainy-platform/backend/business_enablement/business_orchestrator/use_cases/mvp/insights_orchestrator/workflows/structured_analysis_workflow.py`

**Current Backend (Lines 55-65):**
```python
visualizations = [
    {
        "chart_type": "bar_chart",
        "vega_lite_spec": {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", ...},
        "rationale": "Bar chart showing key metrics over quarters."
    }
]
```

**Should Be:**
```python
visualizations = [
    {
        "visualization_id": f"viz_{uuid.uuid4().hex[:8]}",
        "chart_type": "bar",  # recharts type: 'bar' | 'line' | 'pie' | 'area'
        "library": "recharts",  # or 'nivo'
        "title": "Quarterly Metrics Comparison",
        "rationale": "Bar chart showing key metrics over quarters.",
        "chart_data": [
            {"name": "Q1", "value": 100, "Revenue": 100, "Profit": 20},
            {"name": "Q2", "value": 120, "Revenue": 120, "Profit": 25},
            {"name": "Q3", "value": 150, "Revenue": 150, "Profit": 35},
            {"name": "Q4", "value": 130, "Revenue": 130, "Profit": 30}
        ],
        "x_axis_key": "name",
        "data_key": "value",  # or array of keys for multi-series
        "colors": ["#3b82f6", "#10b981", "#f59e0b"]
    }
]
```

**Action Required:**
1. **Frontend:** Replace Vega-Lite placeholder with `ChartComponent` (~20 lines)
2. **Backend:** Update all 3 workflows to output Recharts format instead of Vega-Lite (~50 lines)
3. **API Contract:** Update `API_CONTRACT_INSIGHTS_PILLAR.md` to reflect Recharts spec

---

## 3. NLP Queries - Needs Full Implementation ‚ö†Ô∏è

### **Current State: Placeholder Only**

**Backend Implementation:**
```python
# symphainy-platform/backend/business_enablement/business_orchestrator/use_cases/mvp/insights_orchestrator/insights_orchestrator.py
async def query_analysis_results(
    self,
    query: str,
    analysis_id: str,
    query_type: Optional[str] = None
) -> Dict[str, Any]:
    """Query analysis results using natural language (NEW semantic API method)."""
    
    # TODO: Implement actual NLP query processing
    # For now, return placeholder response
    query_id = f"query_{int(datetime.utcnow().timestamp())}_{analysis_id[:8]}"
    
    return {
        "success": True,
        "query_id": query_id,
        "result": {
            "type": "text",
            "explanation": f"Query processed: '{query}'. NLP query processing will be implemented in future iteration.",
            "data": None
        },
        "follow_up_suggestions": [
            "What are the key trends?",
            "Show me a summary",
            "What recommendations do you have?"
        ]
    }
```

### **What NLP Query Processing Should Do:**

**Example User Queries:**
1. "What were the top 3 revenue drivers in Q3?"
2. "Show me a chart of profit margins by quarter"
3. "Which metrics are trending downward?"
4. "Summarize the key risks identified"
5. "What recommendations have high priority?"

**Expected Behavior:**
- Parse natural language query
- Understand intent (question, chart request, filter, summary)
- Query cached analysis results
- Extract relevant data
- Format response (text explanation + optional table/chart)
- Generate follow-up suggestions

### **Proposed Architecture:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ NLP Query Processing Pipeline                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  1. Query Analysis (Intent Detection)                           ‚îÇ
‚îÇ     ‚îú‚îÄ Question Type: ["what", "show", "which", "summarize"]    ‚îÇ
‚îÇ     ‚îú‚îÄ Entity Extraction: ["Q3", "revenue", "profit margins"]   ‚îÇ
‚îÇ     ‚îî‚îÄ Output Format: ["text", "table", "chart"]                ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  2. Context Retrieval                                            ‚îÇ
‚îÇ     ‚îú‚îÄ Fetch cached analysis by ID                              ‚îÇ
‚îÇ     ‚îú‚îÄ Load relevant sections (summary, insights, tabular)      ‚îÇ
‚îÇ     ‚îî‚îÄ Extract metadata (content_type, source_info)             ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  3. Query Execution                                              ‚îÇ
‚îÇ     ‚îú‚îÄ Text Query ‚Üí Search textual summary                      ‚îÇ
‚îÇ     ‚îú‚îÄ Table Query ‚Üí Filter/aggregate tabular data              ‚îÇ
‚îÇ     ‚îú‚îÄ Chart Query ‚Üí Generate chart spec from data              ‚îÇ
‚îÇ     ‚îî‚îÄ Summary Query ‚Üí Aggregate across all sections            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  4. Response Generation                                          ‚îÇ
‚îÇ     ‚îú‚îÄ Format explanation (natural language)                    ‚îÇ
‚îÇ     ‚îú‚îÄ Include data (if table/chart requested)                  ‚îÇ
‚îÇ     ‚îú‚îÄ Generate follow-up suggestions                           ‚îÇ
‚îÇ     ‚îî‚îÄ Return structured response                               ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Implementation Options:**

#### **Option A: Simple Rule-Based (Fast, Limited)**
```python
class SimpleNLPQueryProcessor:
    """Rule-based query processing for common patterns."""
    
    QUERY_PATTERNS = {
        r"top (\d+) (.+)": "top_n_query",
        r"show.*chart.*(.+)": "chart_request",
        r"what.*trend.*(.+)": "trend_analysis",
        r"summarize (.+)": "summarize_section",
        r"which.*high.*": "high_priority_filter"
    }
    
    def parse_query(self, query: str) -> dict:
        """Parse query using regex patterns."""
        for pattern, intent in self.QUERY_PATTERNS.items():
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                return {
                    "intent": intent,
                    "entities": match.groups(),
                    "confidence": 0.9
                }
        return {"intent": "general_question", "entities": [], "confidence": 0.5}
    
    def execute_query(self, intent: str, entities: list, analysis: dict) -> dict:
        """Execute query based on intent."""
        if intent == "top_n_query":
            n = int(entities[0])
            metric = entities[1]
            # Extract top N items from tabular data
            # ...
        elif intent == "chart_request":
            # Generate chart from relevant data
            # ...
        # ... more intent handlers
```

**Pros:** Fast, predictable, no ML dependencies  
**Cons:** Limited flexibility, doesn't handle varied phrasing

#### **Option B: LLM-Based (Flexible, Resource-Intensive)**
```python
class LLMNLPQueryProcessor:
    """LLM-based query processing using function calling."""
    
    def __init__(self, llm_client):
        self.llm = llm_client
    
    async def parse_query(self, query: str, analysis_context: dict) -> dict:
        """Use LLM to understand query intent."""
        
        system_prompt = """
        You are a query analyzer for business analytics.
        Parse the user's query and determine:
        1. Query intent (question, chart_request, filter, summary)
        2. Entities mentioned (metrics, time periods, categories)
        3. Desired output format (text, table, chart)
        4. Relevant sections of analysis to query
        """
        
        functions = [
            {
                "name": "parse_analytics_query",
                "description": "Parse a natural language analytics query",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "intent": {"type": "string", "enum": ["question", "chart_request", "filter", "summary"]},
                        "entities": {"type": "array", "items": {"type": "string"}},
                        "output_format": {"type": "string", "enum": ["text", "table", "chart"]},
                        "relevant_sections": {"type": "array", "items": {"type": "string"}}
                    }
                }
            }
        ]
        
        response = await self.llm.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Query: {query}\nAnalysis Context: {json.dumps(analysis_context)}"}
            ],
            functions=functions,
            function_call={"name": "parse_analytics_query"}
        )
        
        return json.loads(response.choices[0].message.function_call.arguments)
    
    async def execute_query(self, parsed_query: dict, analysis: dict) -> dict:
        """Execute the parsed query against analysis data."""
        # Use LLM to generate response based on intent and data
        # ...
```

**Pros:** Flexible, handles varied phrasing, generates natural responses  
**Cons:** Requires API calls, slower, cost per query

#### **Option C: Hybrid (Balanced)**
```python
class HybridNLPQueryProcessor:
    """Hybrid approach: Rules for common patterns, LLM for complex queries."""
    
    def __init__(self, llm_client):
        self.simple_processor = SimpleNLPQueryProcessor()
        self.llm_processor = LLMNLPQueryProcessor(llm_client)
    
    async def process_query(self, query: str, analysis: dict) -> dict:
        """Route to appropriate processor based on query complexity."""
        
        # Try simple processor first
        simple_result = self.simple_processor.parse_query(query)
        
        if simple_result["confidence"] > 0.8:
            # High confidence, use rule-based
            return self.simple_processor.execute_query(
                simple_result["intent"],
                simple_result["entities"],
                analysis
            )
        else:
            # Low confidence, fall back to LLM
            return await self.llm_processor.parse_query(query, analysis)
```

**Pros:** Fast for common queries, flexible for complex ones  
**Cons:** More complex to maintain

### **Recommended Approach:**

**Phase 1: Simple Rule-Based (Quick Win)**
- Implement 10-15 common query patterns
- Support basic operations (top N, filter, chart generation)
- Can be built in 1-2 days
- Covers 70% of expected use cases

**Phase 2: Add LLM Fallback (Future Enhancement)**
- Add LLM processing for unmatched queries
- Use function calling for structured responses
- Requires LLM API integration
- Can be added incrementally

**Action Required:**
1. Create `NLPQueryProcessor` class in `enabling_services/`
2. Implement rule-based query parsing
3. Add query execution logic (filter, aggregate, chart generation)
4. Update `insights_orchestrator.py` to use processor
5. Estimated: 200-300 lines of code, 1-2 days work

---

## 4. Export Reports - Clarification Needed ‚ÑπÔ∏è

### **Current State: Placeholder in Backend**

**Backend Router:**
```python
# symphainy-platform/backend/experience/api/semantic/insights_pillar_router.py
@router.post("/export-analysis-report", response_model=ExportReportResponse)
async def export_analysis_report_endpoint(
    request: ExportReportRequest,
    session_token: Optional[str] = Header(None, alias="X-Session-Token")
):
    """Exports a generated analysis report in various formats (PDF, DOCX, CSV, JSON)."""
    
    # TODO: Implement actual report generation logic
    # For now, simulate report generation
    report_id = f"report_{request.analysis_id}_{request.export_format}_{datetime.utcnow().timestamp()}"
    download_link = f"/downloads/{report_id}.{request.export_format}"
    
    return ExportReportResponse(
        success=True,
        report_id=report_id,
        download_link=download_link,
        message=f"Report generation for {request.analysis_id} in {request.export_format} format initiated."
    )
```

**Frontend Usage:**
```typescript
// Currently mentioned in "What's next" section of page.tsx
<li>‚Ä¢ <span className="font-medium">Export Reports:</span> Download your analysis in various formats (coming soon)</li>
```

### **Questions for Clarification:**

1. **What formats are required?**
   - PDF (formatted report with charts)?
   - DOCX (editable Word document)?
   - CSV (tabular data only)?
   - JSON (raw data)?
   - PowerPoint (presentation)?

2. **What should be included in the export?**
   - Full analysis (all sections)?
   - Selective export (choose sections)?
   - Charts/visualizations included?
   - AAR analysis included?
   - Metadata and timestamps?

3. **How should charts be rendered in exports?**
   - Static images (PNG/SVG)?
   - Embedded interactive charts?
   - Data tables instead of charts?

4. **Is this a priority feature?**
   - Critical for MVP?
   - Nice-to-have for later?
   - Required for specific use cases (e.g., Navy AAR reports)?

5. **Any specific formatting requirements?**
   - Branded templates?
   - Specific layouts?
   - Compliance/classification headers (for Navy)?

### **Implementation Considerations:**

**For PDF:**
- Library: `reportlab` or `weasyprint` (Python)
- Generate HTML ‚Üí Convert to PDF
- Include charts as embedded images
- Support custom templates

**For DOCX:**
- Library: `python-docx`
- Structured document with sections
- Embed charts as images
- Support Navy AAR template

**For CSV:**
- Simple: export tabular data only
- Multiple CSVs in ZIP for complex data

**For JSON:**
- Simple: serialize analysis response
- Include all data structures

**Estimated Complexity:**
- PDF: Medium (2-3 days with templates)
- DOCX: Medium (2-3 days with templates)
- CSV: Low (few hours)
- JSON: Low (1 hour)

### **Recommended Approach:**

**Phase 1: JSON + CSV (Quick Win)**
- Implement JSON export (serialize existing response)
- Implement CSV export (tabular data only)
- Add download endpoint in FastAPI
- Can be built in 1 day

**Phase 2: PDF/DOCX (Future)**
- Design report templates
- Implement PDF generation with charts
- Implement DOCX generation
- Add Navy AAR template option
- Estimated: 4-5 days

**Action Required:**
1. Clarify requirements with stakeholders
2. Prioritize formats based on user needs
3. Decide if this blocks MVP or can be deferred

---

## üìä Priority Summary

| TODO | Priority | Effort | Impact | Recommendation |
|------|----------|--------|--------|----------------|
| **1. File Selection** | üî¥ **HIGH** | Low (30 lines) | High (UX blocker) | **Fix immediately** |
| **2. Visualization** | üî¥ **CRITICAL** | Medium (70 lines) | Critical (wrong library) | **Fix immediately** |
| **3. NLP Queries** | üü° **MEDIUM** | High (200-300 lines) | Medium (enhancement) | **Phase 1: Simple rules** |
| **4. Export Reports** | üü¢ **LOW** | Varies | Low (nice-to-have) | **Clarify requirements first** |

---

## üöÄ Recommended Action Plan

### **Immediate (Today):**
1. ‚úÖ **Fix File Selection** (30 mins)
   - Add `ContentAPIManager` to `InsightsFileSelector`
   - Remove placeholder files
   - Test with real file list

2. ‚úÖ **Fix Visualization Library** (2 hours)
   - Replace Vega-Lite with `ChartComponent`
   - Update backend workflows (3 files)
   - Update API contract documentation
   - Test chart rendering

### **Short Term (This Week):**
3. ‚ö†Ô∏è **Implement Simple NLP Queries** (1-2 days)
   - Create rule-based `NLPQueryProcessor`
   - Support 10-15 common query patterns
   - Integrate with orchestrator
   - Test with sample queries

### **Clarify & Plan (This Week):**
4. ‚ÑπÔ∏è **Export Reports Requirements** (1 meeting)
   - Meet with stakeholders
   - Clarify format requirements
   - Prioritize based on MVP needs
   - Create implementation plan if needed

---

## üìö Files Requiring Updates

### **Frontend (3 files):**
1. `symphainy-frontend/app/pillars/insights/components/InsightsFileSelector.tsx` (~30 lines)
2. `symphainy-frontend/app/pillars/insights/components/InsightsSummaryDisplay.tsx` (~20 lines)
3. `symphainy-frontend/lib/api/insights.ts` (interfaces - minimal changes)

### **Backend (4-5 files):**
1. `symphainy-platform/backend/business_enablement/business_orchestrator/use_cases/mvp/insights_orchestrator/workflows/structured_analysis_workflow.py` (~20 lines)
2. `symphainy-platform/backend/business_enablement/business_orchestrator/use_cases/mvp/insights_orchestrator/workflows/unstructured_analysis_workflow.py` (~20 lines)
3. `symphainy-platform/backend/business_enablement/business_orchestrator/use_cases/mvp/insights_orchestrator/workflows/hybrid_analysis_workflow.py` (~10 lines)
4. `symphainy-platform/backend/business_enablement/enabling_services/nlp_query_processor/` (new service, ~200-300 lines)
5. `symphainy-platform/backend/business_enablement/business_orchestrator/use_cases/mvp/insights_orchestrator/insights_orchestrator.py` (~50 lines update)

### **Documentation (2 files):**
1. `API_CONTRACT_INSIGHTS_PILLAR.md` (update visualization spec)
2. `PHASE_3_COMPLETE.md` (update with corrections)

---

## üí° Lessons Learned

1. **Always verify library assumptions** - We assumed Vega-Lite but platform uses Recharts
2. **Check existing implementations** - FileDashboard pattern was already solved
3. **Placeholder != Priority** - NLP queries are placeholder but may not block MVP
4. **Requirements matter** - Export feature needs clarification before building

---

**Next Steps:** Would you like me to:
1. Fix File Selection immediately?
2. Fix Visualization library immediately?
3. Create detailed NLP Query implementation plan?
4. Schedule requirements meeting for Export Reports?

All 4? Let me know your priority!

